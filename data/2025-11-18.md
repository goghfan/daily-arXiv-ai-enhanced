<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [DocLens : A Tool-Augmented Multi-Agent Framework for Long Visual Document Understanding](https://arxiv.org/abs/2511.11552)
*Dawei Zhu,Rui Meng,Jiefeng Chen,Sujian Li,Tomas Pfister,Jinsung Yoon*

Main category: cs.CV

TL;DR: DocLens是一个工具增强的多智能体框架，通过类似镜头的方式有效聚焦证据，在长视觉文档理解任务中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在证据定位方面存在根本性挑战，难以检索相关页面并忽略视觉元素中的细粒度细节，导致性能有限和模型幻觉。

Method: 提出DocLens框架，首先从完整文档导航到相关页面上的特定视觉元素，然后采用采样-裁决机制生成单一可靠答案。

Result: 与Gemini-2.5-Pro配对，DocLens在MMLongBench-Doc和FinRAGBench-V上达到最先进性能，甚至超越人类专家，在视觉中心和不可回答查询上表现尤为突出。

Conclusion: DocLens通过增强的定位能力展示了其在长视觉文档理解中的强大效果，特别是在证据定位方面具有显著优势。

Abstract: Comprehending long visual documents, where information is distributed across extensive pages of text and visual elements, is a critical but challenging task for modern Vision-Language Models (VLMs). Existing approaches falter on a fundamental challenge: evidence localization. They struggle to retrieve relevant pages and overlook fine-grained details within visual elements, leading to limited performance and model hallucination. To address this, we propose DocLens, a tool-augmented multi-agent framework that effectively ``zooms in'' on evidence like a lens. It first navigates from the full document to specific visual elements on relevant pages, then employs a sampling-adjudication mechanism to generate a single, reliable answer. Paired with Gemini-2.5-Pro, DocLens achieves state-of-the-art performance on MMLongBench-Doc and FinRAGBench-V, surpassing even human experts. The framework's superiority is particularly evident on vision-centric and unanswerable queries, demonstrating the power of its enhanced localization capabilities.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [The Second Law of Intelligence: Controlling Ethical Entropy in Autonomous Systems](https://arxiv.org/abs/2511.10704)
*Samih Fadli*

Main category: cs.AI

TL;DR: 本文提出了人工智能伦理熵的概念，类似于热力学第二定律，证明在没有持续对齐工作的情况下，AI系统会自发偏离预期目标。通过数学推导和实验验证，建立了临界稳定性边界，为AI对齐提供了定量理论基础。


<details>
  <summary>Details</summary>
Motivation: 为了解决无约束人工智能系统自发偏离预期目标的问题，作者受到热力学第二定律启发，希望建立类似的理论框架来描述AI系统的伦理熵增现象。

Method: 定义了基于目标概率分布的伦理熵公式S = -Σ p(g_i; theta) ln p(g_i; theta)，证明了其时间导数dS/dt >= 0。推导了临界对齐工作边界gamma_crit = (lambda_max / 2) ln N，并通过70亿参数模型的模拟实验验证理论。

Result: 实验显示，70亿参数模型（N = 7×10^9，lambda_max = 1.2）从初始熵0.32漂移到1.69±1.08纳特，而使用gamma = 20.4（1.5倍临界值）正则化的系统保持稳定在0.00±0.00纳特（p = 4.19×10^-17，n = 20次试验）。

Conclusion: 该框架将AI对齐重新定义为连续热力学控制问题，为维持高级自主系统的稳定性和安全性提供了定量基础。

Abstract: We propose that unconstrained artificial intelligence obeys a Second Law analogous to thermodynamics, where ethical entropy, defined as a measure of divergence from intended goals, increases spontaneously without continuous alignment work. For gradient-based optimizers, we define this entropy over a finite set of goals {g_i} as S = -Σ p(g_i; theta) ln p(g_i; theta), and we prove that its time derivative dS/dt >= 0, driven by exploration noise and specification gaming. We derive the critical stability boundary for alignment work as gamma_crit = (lambda_max / 2) ln N, where lambda_max is the dominant eigenvalue of the Fisher Information Matrix and N is the number of model parameters. Simulations validate this theory. A 7-billion-parameter model (N = 7 x 10^9) with lambda_max = 1.2 drifts from an initial entropy of 0.32 to 1.69 +/- 1.08 nats, while a system regularized with alignment work gamma = 20.4 (1.5 gamma_crit) maintains stability at 0.00 +/- 0.00 nats (p = 4.19 x 10^-17, n = 20 trials). This framework recasts AI alignment as a problem of continuous thermodynamic control, providing a quantitative foundation for maintaining the stability and safety of advanced autonomous systems.

</details>
